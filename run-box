#!/bin/bash

#PBS -A UCUB0166 
#PBS -N box-model
#PBS -q main
#PBS -j oe
#PBS -l job_priority=economy
#PBS -l walltime=12:00:00
#PBS -l select=1:ncpus=64:mpiprocs=1:ngpu=1:mem=84GB

rm -rf outputs
mkdir outputs

# Set Julia threading (optional: for non-MPI threading)
export JULIA_NUM_PRECOMPILE_TASKS=64
export JULIA_NUM_THREADS=64

# Load only CPU-relevant modules
module --force purge
module load ncarenv/23.09 nvhpc/24.7 cuda/12.2.1 cray-mpich/8.1.29

module list

# Avoid all GPU-related settings
export MPICH_GPU_SUPPORT_ENABLED=1
export MPICH_GPU_MANAGED_MEMORY_SUPPORT_ENABLED=1
export JULIA_MPI_HAS_CUDA=true
export PALS_TRANSFER=false
export JULIA_CUDA_MEMORY_POOL=none


# Write down a script that binds MPI processes to GPUs (taken from Derecho documentation)
cat > launch.sh << EoF_s
#! /bin/bash

export MPICH_GPU_SUPPORT_ENABLED=1
export MPICH_GPU_MANAGED_MEMORY_SUPPORT_ENABLED=1
export LOCAL_RANK=\${PMI_LOCAL_RANK}
export GLOBAL_RANK=\${PMI_RANK}
export CUDA_VISIBLE_DEVICES=\$(expr \${LOCAL_RANK} % 4)

echo "Global Rank \${GLOBAL_RANK} / Local Rank \${LOCAL_RANK} / CUDA_VISIBLE_DEVICES=\${CUDA_VISIBLE_DEVICES} / \$(hostname)"

exec \$*
EoF_s

chmod +x launch.sh

# Now to make our julia environment work:
# 1. Instantiate (we only need to do this once, but this also may be the first time you are running this code)
julia --project -e 'using Pkg; Pkg.instantiate()'
julia --project -e 'using MPIPreferences; MPIPreferences.use_system_binary(vendor="cray", force=true)'
julia --project -e 'using MPI; using CUDA; CUDA.precompile_runtime()'
# 2. Add some packages to the environment that we need to use
julia --project -e 'using Pkg; Pkg.add("MPI"); Pkg.add("MPIPreferences"); Pkg.add("Oceananigans"); Pkg.add("OceanBioME")'

# Finally, let's run this thing
mpiexec -n 2 ./launch.sh julia --project box-model.jl